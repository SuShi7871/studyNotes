# 机器学习

## 1.人工智能概述

### 1.人工智能起源

图灵测试

达特茅斯会议

### 2.人工智能三个阶段

- 1980年代是正式成形期
- 1990-2010年代是蓬勃发展期
- 2012年之后是深度学习期

### 3.三者的关系

- 机器学习是人工智能的一个实现途径
- 深度学习是机器学习的一个方法发展而来

### 4.主要分支介绍

1.计算机视觉

​		人脸识别

2.自然语言处理

​		语音识别语义识别

3.机器人

### 5.人工智能必备三要素

数据

算法

计算力

### 6.`gpu`、`cpu`

`gpu`--计算密集型

`cpu`--IO密集型

## 2.机器学习

### 1.机器学习的定义

数据
自动分析获得模型
预测
从数据中自动分析获得模型，并利用模型对未知数据进行预测

### 2.工作流程

1.获取数据

2.数据基本处理

3.特征工程

4.机器学习（模型训练）

5.模型评估

#### 1.获取到的数据集介绍

1.专有名词

​		样本、特征目标值（标签值）、特征值

2.数据类型构成

​		类型一：特征值+目标值

​			目标值分为是离散还是连续

​		类型二：只有特征值，没有目标值

3.数据划分

​		训练数据（训练集）--构建模型

​		0.7--0.8

​		测试数据（测试集）--模型评估

​		0.2--0.3

#### 2.数据基本处理

​		对数进行缺失值、去除异常值等处理

#### 3.特征工程

1.定义

​		把数据转换成为机器更容易识别的数据

2.为什么需要特征工程

​		数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已

3.包含内容

​		特征提取

​		特征预处理

​		特征降维

#### 4.机器学习

​		选择合适的算法对模型进行训练

#### 5.模型评估

​		对调练好的模型进行评估

### 3.机器学习算法分类

1.监督学习 

​		就是有特征值，有目标值

​		目标值连续--	回归

​		目标值离散--	分类

2.无监督学习

​		仅有特征值

3.半监督学习

​		有特征值，但是一部分数据有目标值，一部分没有特征值

4.强化学习

​		动态过程，上一步数据的输出是下一步数据的输

​		四要素：agent、action、environment、Reward,

### 4.模型评估

#### 1.分类模型评估

​		准确率：预测正确的数占样本总数的比例。

​		精确率：正确预测为正占全部预测为正的比例

​		召回率：正确预测为正占全部正样本的比例

​		F1-score：主要用于评估模型的稳健性

​		AUC指标：主要用于评估样本人沟衡的情况

#### 2.回归模型评估

- 均方根误差
- 相对平方误差
- 平均绝对误差
- 相对绝对误差
- 决定系数

3.拟合

- 欠拟合
- 过拟合

## 3.机器学习算法

### 1.线性回归算法

### 聚类算法

**聚类算法**：就是把距离作为特征，通过自下而上的迭代方式（距离对比），快速地把一群样本分成几个类别的过程。

**更严谨，专业一些的说法是：**

将相似的对象归到同一个簇中，使得同一个簇内的数据对象的**相似性尽可能大**，同时不在同一个簇中的数据对象的**差异性也尽可能地大**。即聚类后同一类的数据尽可能聚集到一起，不同数据尽量分离。

**聚类是一种无监督学习**

- 对于有标签的数据，我们进行有监督学习，常见的分类任务就是**监督学习**；
- 而对于无标签的数据，我们希望发现无标签的数据中的潜在信息，这就是**无监督学习**。

聚类算法是根据样本之间的相似度，将数据进行归类的。

而相似度的度量方法，可以大致分为：

- 距离相似性度量
- 密度相似性度量
- 连通相似性度量

不同类型的聚类算法，采用的样本间的相似度度量方法是不同的。

####  K-Means

K-Means 即K-均值，定义如下：

对于给定的样本集，按照样本之间的距离大小，将样本集划分为K个簇。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大

K-Means 聚类的步骤如下：

1. 随机的选取K个中心点，代表K个类别；
2. 计算N个样本点和K个中心点之间的欧氏距离；
3. 将每个样本点划分到最近的（欧氏距离最小的）中心点类别中——迭代1；
4. 计算每个类别中样本点的均值，得到K个均值，将K个均值作为新的中心点——迭代2；
5. 重复步骤2、3、4；
6. 满足收敛条件后，得到收敛后的K个中心点（中心点不再变化）。

K-Means 可以用欧式距离，欧式距离很简单，二维平面就是两个点的距离公式，在多维空间里，假设两个样本为`a(x1,x2,x3,x4...xn)，b(y1,y2,y3,y4...yn)`，那么他们之间的欧式距离的计算公式是：
$$
d=\sqrt{\sum_{k=1}^{n}(x_k-y_k)^2}
$$

#### 实现

1.生成一些随机数据点,进行数据集的可视化

```python
import matplotlib.pyplot as plt
from sklearn.datasets._samples_generator import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import calinski_harabasz_score

# 创建数据集
# X为样本特征，Y为样本簇类别， 共1000个样本，每个样本4个特征，共4个簇，
# 簇中心在[-1,-1], [0,0],[1,1], [2,2]， 簇方差分别为[0.4, 0.2, 0.2, 0.2]
X, y = make_blobs(n_samples=1000, n_features=2, centers=[[-1, -1], [0, 0], [1, 1], [2, 2]],
                  cluster_std=[0.4, 0.2, 0.2, 0.2],
                  random_state=9)

# 数据集可视化
plt.scatter(X[:, 0], X[:, 1], marker='o')
plt.show()
```

![1714972661409](D:\software\Typora\typora-user-images\1714972661409.png)

2.使用聚类算法进行实现，调用k_means的api实现聚类，可以通过修改n_cluses来观察聚类效果，然后使用k-means进行聚类,并使用CH方法评估

```python
y_pred = KMeans(n_clusters=4,random_state=9).fit_predict(X)
# 分别尝试n_cluses=2\3\4,然后查看聚类效果
plt.scatter(X[:, 0], X[:, 1], c=y_pred)
plt.show()
# 用Calinski-Harabasz Index评估的聚类分数
print(calinski_harabasz_score(X, y_pred))
```

![1714972822383](D:\software\Typora\typora-user-images\1714972822383.png)

**注意**:

- 由于每次都要计算所有的样本与每一个质心之间的相似度，故在大规模的数据集上，K-Means算法的收敛速度比较慢。

### 朴素贝叶斯

#### 贝叶斯推断

朴素贝叶斯是贝叶斯决策理论的一部分,他是有监督的学习算法，解决的是分类问题，如客户是否流失、是否值得投资、信用等级评定等多分类问题。

对条件概率公式进行变形，可以得到如下形式：
$$
P(A|B)=P(A)\frac{P(B|A)}{P(B)}
$$

- **P(A)称为"先验概率"（Prior probability）**，即在B事件发生之前，我们对A事件概率的一个判断。
- **P(A|B)称为"后验概率"（Posterior probability）**，即在B事件发生之后，我们对A事件概率的重新评估。
- **P(B|A)/P(B)称为"可能性函数"**，这是一个调整因子，使得预估概率更接近真实概率。

所以上述式子可以简单理解为`后验概率＝先验概率ｘ调整因子`，如果调整因子>1那么说明先验概率是被增强的，即先验概率(事件A)的发生的可能性变大,反之，先验概率是被削弱的，即先验概率(事件A)的发生的可能性变小；

#### 朴素贝叶斯推断

朴素贝叶斯对条件个概率分布做了条件独立性的假设。 比如下面的公式，假设有n个特征：
$$
P(a|X) = P(X|a)P(a) =P(x_1,x_2,x_3...x_n|a)P(a)
$$
由于每个特征都是独立的，我们可以进一步拆分公式 
$$
P(a|X) = P(X|a)P(a) =P(x_1,x_2,x_3...x_n|a)P(a)\\=[P(x_1|a)*P(x_2|a)P(x_3|a)...*P(x_n|a)]P(a)
$$

#### 具体实现

首先是创建数据集，这里我们讲几句换放入到list列表之中，作为我们预测的对象

然后是根据我们上一步创建的词汇表，将输入词条向量化，向量的每个元素为1或0
然后是训练朴素贝叶斯分类器训练函数

​	参数:   

-  `trainMatrix` - 训练文档矩阵，即`setOfWords2Vec`返回的`returnVec`构成的矩阵    	
- `trainCategory` - 训练类别标签向量，即`loadDataSet`返回的`classVec`

返回值:    

- `p0Vect` - 非侮辱类的条件概率数组    
- `p1Vect` - 侮辱类的条件概率数组    
- `pAbusive` - 文档属于侮辱类的概率

朴素贝叶斯分类器分类函数

测试朴素贝叶斯分类器

结果

![1716527416884](D:\software\Typora\typora-user-images\1716527416884.png)